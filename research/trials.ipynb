{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/predict_publications/publications_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/test_data.csv')\n",
    "train_df = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/train_data.csv')\n",
    "validation_df = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>likescount</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>symbols_cnt</th>\n",
       "      <th>words_cnt</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>mentions_cnt</th>\n",
       "      <th>links_cnt</th>\n",
       "      <th>emoji_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.136232</td>\n",
       "      <td>60.000054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.138478</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.023627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.030359</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp        lon        lat  hour  day  dayofweek  month  likescount  \\\n",
       "0  1546300800   0.000000   0.000000     0    1          1      1   31.666667   \n",
       "1  1546300800  30.136232  60.000054     0    1          1      1   52.000000   \n",
       "2  1546300800  30.138478  59.835705     0    1          1      1   32.000000   \n",
       "3  1546300800  30.142969  60.023627     0    1          1      1   77.666667   \n",
       "4  1546300800  30.142969  60.030359     0    1          1      1   19.000000   \n",
       "\n",
       "   commentscount  symbols_cnt  words_cnt  hashtags_cnt  mentions_cnt  \\\n",
       "0       1.666667    51.333333   2.000000      2.000000           0.0   \n",
       "1       1.000000    28.000000   0.500000      2.000000           0.0   \n",
       "2       0.333333    46.000000   2.333333      3.000000           0.0   \n",
       "3       3.333333    34.666667   2.666667      0.666667           0.0   \n",
       "4       3.000000     0.000000   0.000000      0.000000           0.0   \n",
       "\n",
       "   links_cnt  emoji_cnt  \n",
       "0        0.0   0.000000  \n",
       "1        0.0   0.500000  \n",
       "2        0.0   1.333333  \n",
       "3        0.0   1.666667  \n",
       "4        0.0   0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'timestamp' to a datetime format\n",
    "train_df['date'] = pd.to_datetime(train_df['timestamp'], unit='s')\n",
    "\n",
    "# Extracting temporal features from the 'date' column\n",
    "train_df['hour'] = train_df['date'].dt.hour\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df['dayofweek'] = train_df['date'].dt.dayofweek\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "\n",
    "# Now, aggregate data based on 'timestamp', 'lat', and 'lon'\n",
    "agg_columns = {\n",
    "    'likescount': 'mean',\n",
    "    'commentscount': 'mean',\n",
    "    'symbols_cnt': 'mean',\n",
    "    'words_cnt': 'mean',\n",
    "    'hashtags_cnt': 'mean',\n",
    "    'mentions_cnt': 'mean',\n",
    "    'links_cnt': 'mean',\n",
    "    'emoji_cnt': 'mean',\n",
    "}\n",
    "\n",
    "grouped_data = train_df.groupby(['timestamp', 'lon', 'lat', 'hour', 'day', 'dayofweek', 'month']).agg(agg_columns).reset_index()\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>likescount</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>symbols_cnt</th>\n",
       "      <th>words_cnt</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>mentions_cnt</th>\n",
       "      <th>links_cnt</th>\n",
       "      <th>emoji_cnt</th>\n",
       "      <th>publication_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.136232</td>\n",
       "      <td>60.000054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.138478</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.023627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.030359</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp        lon        lat  hour  day  dayofweek  month  likescount  \\\n",
       "0  1546300800   0.000000   0.000000     0    1          1      1   31.666667   \n",
       "1  1546300800  30.136232  60.000054     0    1          1      1   52.000000   \n",
       "2  1546300800  30.138478  59.835705     0    1          1      1   32.000000   \n",
       "3  1546300800  30.142969  60.023627     0    1          1      1   77.666667   \n",
       "4  1546300800  30.142969  60.030359     0    1          1      1   19.000000   \n",
       "\n",
       "   commentscount  symbols_cnt  words_cnt  hashtags_cnt  mentions_cnt  \\\n",
       "0       1.666667    51.333333   2.000000      2.000000           0.0   \n",
       "1       1.000000    28.000000   0.500000      2.000000           0.0   \n",
       "2       0.333333    46.000000   2.333333      3.000000           0.0   \n",
       "3       3.333333    34.666667   2.666667      0.666667           0.0   \n",
       "4       3.000000     0.000000   0.000000      0.000000           0.0   \n",
       "\n",
       "   links_cnt  emoji_cnt  publication_count  \n",
       "0        0.0   0.000000                  3  \n",
       "1        0.0   0.500000                  2  \n",
       "2        0.0   1.333333                  3  \n",
       "3        0.0   1.666667                  3  \n",
       "4        0.0   0.000000                  1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data['publication_count'] = train_df.groupby(['timestamp', 'lon', 'lat']).size().values\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'timestamp' as it's strongly correlated with other time features and may cause data leakage\n",
    "X_train = grouped_data.drop(['publication_count', 'timestamp'], axis=1)\n",
    "y_train = grouped_data['publication_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3635541, 14), (3635541,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3635541 entries, 0 to 3635540\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   lon            float64\n",
      " 1   lat            float64\n",
      " 2   hour           int32  \n",
      " 3   day            int32  \n",
      " 4   dayofweek      int32  \n",
      " 5   month          int32  \n",
      " 6   likescount     float64\n",
      " 7   commentscount  float64\n",
      " 8   symbols_cnt    float64\n",
      " 9   words_cnt      float64\n",
      " 10  hashtags_cnt   float64\n",
      " 11  mentions_cnt   float64\n",
      " 12  links_cnt      float64\n",
      " 13  emoji_cnt      float64\n",
      "dtypes: float64(10), int32(4)\n",
      "memory usage: 332.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'hour' column to a datetime format\n",
    "test_data['date'] = pd.to_datetime(test_data['hour'], unit='s')\n",
    "\n",
    "# Drop the original 'hour' column which contains the timestamp\n",
    "test_data.drop(columns=['hour'], inplace=True)\n",
    "\n",
    "# Extract the datetime features from the 'date' column\n",
    "test_data['hour'] = test_data['date'].dt.hour\n",
    "test_data['day'] = test_data['date'].dt.day\n",
    "test_data['dayofweek'] = test_data['date'].dt.dayofweek\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "\n",
    "# Drop the 'date' column as it's not needed for prediction\n",
    "test_data.drop(columns=['date'], inplace=True)\n",
    "\n",
    "train_df_for_testing = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/train_data.csv')\n",
    "\n",
    "# Set 'point' as the index for both datasets\n",
    "train_df_for_testing.set_index('point', inplace=True)\n",
    "test_data.set_index('point', inplace=True)\n",
    "\n",
    "# List of features to create in the test dataset\n",
    "features_to_create = ['likescount', 'commentscount', 'symbols_cnt', 'words_cnt', \n",
    "                      'hashtags_cnt', 'mentions_cnt', 'links_cnt', 'emoji_cnt']\n",
    "\n",
    "# Aggregate the training dataset based on 'point' and compute the median for each feature\n",
    "aggregated_data = train_df_for_testing[features_to_create].groupby('point').median()\n",
    "\n",
    "# Merge the test dataset with the aggregated training data on 'point'\n",
    "test_data = test_data.join(aggregated_data, on='point', how='left')\n",
    "\n",
    "# Reset index for both datasets after the operations\n",
    "train_df_for_testing.reset_index(inplace=True)\n",
    "test_data.reset_index(inplace=True)\n",
    "\n",
    "X_test = test_data.drop(['sum', 'point', 'error'], axis=1)\n",
    "y_test = test_data['sum']\n",
    "X_test = X_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 14), (700,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   lon            700 non-null    float64\n",
      " 1   lat            700 non-null    float64\n",
      " 2   hour           700 non-null    int32  \n",
      " 3   day            700 non-null    int32  \n",
      " 4   dayofweek      700 non-null    int32  \n",
      " 5   month          700 non-null    int32  \n",
      " 6   likescount     700 non-null    float64\n",
      " 7   commentscount  700 non-null    float64\n",
      " 8   symbols_cnt    700 non-null    float64\n",
      " 9   words_cnt      700 non-null    float64\n",
      " 10  hashtags_cnt   700 non-null    float64\n",
      " 11  mentions_cnt   700 non-null    float64\n",
      " 12  links_cnt      700 non-null    float64\n",
      " 13  emoji_cnt      700 non-null    float64\n",
      "dtypes: float64(10), int32(4)\n",
      "memory usage: 65.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>likescount</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>symbols_cnt</th>\n",
       "      <th>words_cnt</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>mentions_cnt</th>\n",
       "      <th>links_cnt</th>\n",
       "      <th>emoji_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.331616</td>\n",
       "      <td>59.934863</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.329370</td>\n",
       "      <td>59.940488</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.297929</td>\n",
       "      <td>59.905597</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.356319</td>\n",
       "      <td>59.921358</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.315895</td>\n",
       "      <td>59.939363</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lon        lat  hour  day  dayofweek  month  likescount  \\\n",
       "0  30.331616  59.934863    10   26          2      2        44.0   \n",
       "1  30.329370  59.940488    11   17          0      2        41.0   \n",
       "2  30.297929  59.905597    16   12          2      2        28.0   \n",
       "3  30.356319  59.921358    13   12          2      2        48.0   \n",
       "4  30.315895  59.939363    13   15          5      2        47.0   \n",
       "\n",
       "   commentscount  symbols_cnt  words_cnt  hashtags_cnt  mentions_cnt  \\\n",
       "0            1.0         73.0        4.0           0.0           0.0   \n",
       "1            1.0         47.0        2.0           0.0           0.0   \n",
       "2            0.0         42.0        2.0           0.0           0.0   \n",
       "3            1.0        110.0        6.0           0.0           0.0   \n",
       "4            1.0         49.0        2.0           0.0           0.0   \n",
       "\n",
       "   links_cnt  emoji_cnt  \n",
       "0        0.0        1.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        1.0  \n",
       "4        0.0        0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE: 7.1921547458456745\n",
      "RMSE: 10.642302552301723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "\n",
    "# Calculating the relative error for the Gradient Boosting model predictions\n",
    "rf_relative_errors = np.abs(rf_predictions - y_test) / rf_predictions\n",
    "rf_average_relative_error = rf_relative_errors.mean()\n",
    "\n",
    "\n",
    "print(f\"ARE: {rf_average_relative_error}\")\n",
    "print(f\"RMSE: {rf_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.0895527640998049, max_depth=8,\n",
       "                          min_samples_leaf=4, min_samples_split=20,\n",
       "                          random_state=42, subsample=0.5970487514167024)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.0895527640998049, max_depth=8,\n",
       "                          min_samples_leaf=4, min_samples_split=20,\n",
       "                          random_state=42, subsample=0.5970487514167024)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.0895527640998049, max_depth=8,\n",
       "                          min_samples_leaf=4, min_samples_split=20,\n",
       "                          random_state=42, subsample=0.5970487514167024)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=8, learning_rate=0.0895527640998049, subsample=0.5970487514167024, min_samples_split=20, min_samples_leaf=4, random_state=42)\n",
    "\n",
    "gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.441987344758175"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using the Gradient Boosting model\n",
    "gb_predictions = gb_model.predict(X_test)  # gb_model is already loaded and trained\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_predictions))\n",
    "\n",
    "# Calculating the relative error for the Gradient Boosting model predictions\n",
    "gb_relative_errors = np.abs(gb_predictions - y_test) / gb_predictions\n",
    "gb_average_relative_error = gb_relative_errors.mean()\n",
    "gb_average_relative_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshaping data for LSTM [samples, time steps, features]\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18936/18936 - 68s - loss: 6.0040 - val_loss: 15.3487 - 68s/epoch - 4ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/predict_publications_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18936/18936 - 37s - loss: 5.6181 - val_loss: 15.5636 - 37s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "18936/18936 - 35s - loss: 5.5254 - val_loss: 15.3149 - 35s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "18936/18936 - 32s - loss: 5.4839 - val_loss: 15.2680 - 32s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "18936/18936 - 41s - loss: 5.4545 - val_loss: 15.3143 - 41s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "18936/18936 - 33s - loss: 5.4114 - val_loss: 15.1145 - 33s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "18936/18936 - 32s - loss: 5.1136 - val_loss: 13.8061 - 32s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "18936/18936 - 31s - loss: 4.7541 - val_loss: 12.9232 - 31s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "18936/18936 - 32s - loss: 4.5706 - val_loss: 12.1905 - 32s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "18936/18936 - 35s - loss: 4.4449 - val_loss: 12.0020 - 35s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37871/37871 - 61s - loss: 9.9092 - val_loss: 19.7933 - 61s/epoch - 2ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/predict_publications_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37871/37871 - 72s - loss: 9.4470 - val_loss: 19.7132 - 72s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "37871/37871 - 73s - loss: 9.3692 - val_loss: 19.4408 - 73s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "37871/37871 - 76s - loss: 8.8962 - val_loss: 18.7532 - 76s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "37871/37871 - 56s - loss: 7.9712 - val_loss: 16.4765 - 56s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "37871/37871 - 61s - loss: 7.5360 - val_loss: 15.0554 - 61s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "37871/37871 - 60s - loss: 7.2425 - val_loss: 15.5081 - 60s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "37871/37871 - 81s - loss: 7.1118 - val_loss: 15.1979 - 81s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "37871/37871 - 60s - loss: 6.9740 - val_loss: 14.5343 - 60s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "37871/37871 - 56s - loss: 6.9097 - val_loss: 13.9994 - 56s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56806/56806 - 120s - loss: 12.8946 - val_loss: 13.9314 - 120s/epoch - 2ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/predict_publications_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56806/56806 - 80s - loss: 12.4918 - val_loss: 13.7600 - 80s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "56806/56806 - 80s - loss: 11.3348 - val_loss: 11.8349 - 80s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "56806/56806 - 79s - loss: 10.1577 - val_loss: 10.8648 - 79s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "56806/56806 - 81s - loss: 9.6387 - val_loss: 10.3705 - 81s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "56806/56806 - 80s - loss: 9.3404 - val_loss: 10.1775 - 80s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "56806/56806 - 77s - loss: 9.1189 - val_loss: 9.9343 - 77s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "56806/56806 - 94s - loss: 9.0156 - val_loss: 9.7985 - 94s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "56806/56806 - 77s - loss: 8.9620 - val_loss: 9.8031 - 77s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "56806/56806 - 80s - loss: 8.9009 - val_loss: 9.7179 - 80s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "75741/75741 - 115s - loss: 13.0978 - val_loss: 17.2161 - 115s/epoch - 2ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/predict_publications_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75741/75741 - 110s - loss: 12.5507 - val_loss: 16.2462 - 110s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "75741/75741 - 133s - loss: 10.6992 - val_loss: 14.9405 - 133s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "75741/75741 - 100s - loss: 9.9339 - val_loss: 14.3591 - 100s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "75741/75741 - 110s - loss: 9.5620 - val_loss: 13.8411 - 110s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "75741/75741 - 111s - loss: 9.3858 - val_loss: 13.7843 - 111s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "75741/75741 - 99s - loss: 9.2028 - val_loss: 13.7589 - 99s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "75741/75741 - 102s - loss: 9.1306 - val_loss: 13.5464 - 102s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "75741/75741 - 112s - loss: 9.0176 - val_loss: 13.4089 - 112s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "75741/75741 - 102s - loss: 8.9312 - val_loss: 13.4283 - 102s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/predict_publications_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94676/94676 - 140s - loss: 13.8038 - val_loss: 24.9670 - 140s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "94676/94676 - 123s - loss: 11.7782 - val_loss: 26.4387 - 123s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "94676/94676 - 149s - loss: 10.7609 - val_loss: 43.0446 - 149s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "94676/94676 - 127s - loss: 10.4327 - val_loss: 29.6376 - 127s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "94676/94676 - 121s - loss: 10.2149 - val_loss: 20.0634 - 121s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "94676/94676 - 127s - loss: 10.1091 - val_loss: 19.2332 - 127s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "94676/94676 - 125s - loss: 9.9741 - val_loss: 18.0149 - 125s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "94676/94676 - 145s - loss: 9.9051 - val_loss: 18.4289 - 145s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "94676/94676 - 126s - loss: 9.8098 - val_loss: 18.2015 - 126s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "94676/94676 - 152s - loss: 9.7854 - val_loss: 17.0211 - 152s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import clone_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    return model\n",
    "\n",
    "best_model = None\n",
    "lowest_val_loss = float('inf')\n",
    "\n",
    "# Time Series Split\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, val_index in tscv.split(X_train_reshaped):\n",
    "    X_train_fold, X_val_fold = X_train_reshaped[train_index], X_train_reshaped[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = create_lstm_model()\n",
    "    \n",
    "    # Use ModelCheckpoint to save the model with the lowest validation loss\n",
    "    checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint], verbose=2, shuffle=False)\n",
    "    \n",
    "    # Check if this fold's model is better than the previous best model\n",
    "    val_loss = model.history.history['val_loss'][-1]\n",
    "    if val_loss < lowest_val_loss:\n",
    "        best_model = clone_model(model)\n",
    "        best_model.load_weights('best_model.h5')\n",
    "        best_model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "        lowest_val_loss = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 883us/step\n",
      "RMSE on the validation set: 9.6844950802608\n",
      "Average Relative Error on the validation set: 3.0718928774431853\n"
     ]
    }
   ],
   "source": [
    "# Reshape X_test for the LSTM model\n",
    "X_test_reshaped = scaler.transform(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Predictions on the validation set\n",
    "lstm_predictions = best_model.predict(X_test_reshaped).flatten()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "print(f\"RMSE on the validation set: {rmse}\")\n",
    "\n",
    "# Calculate Average Relative Error using the provided formula\n",
    "epsilon = 1e-10  # To ensure we're not dividing by zero\n",
    "are = np.mean(np.abs(y_test - lstm_predictions) / (lstm_predictions + epsilon))\n",
    "print(f\"Average Relative Error on the validation set: {are}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_publications_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
