{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/predict_publications/publications_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/test_data.csv')\n",
    "train_data = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/train_data.csv')\n",
    "validation_data = pd.read_csv('/Users/macbookpro/Documents/predict_publications/publications_prediction/data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>point</th>\n",
       "      <th>hour</th>\n",
       "      <th>likescount</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>symbols_cnt</th>\n",
       "      <th>words_cnt</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>mentions_cnt</th>\n",
       "      <th>links_cnt</th>\n",
       "      <th>emoji_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0101000020E61000000000000000000000000000000000...</td>\n",
       "      <td>0</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.136232</td>\n",
       "      <td>60.000054</td>\n",
       "      <td>0101000020E6100000B8E59619E0223E40ABB649C80100...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.138478</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>0101000020E610000077D0A94773233E4097654065F8EA...</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.023627</td>\n",
       "      <td>0101000020E6100000F5A5CFA399243E400B9A5B330603...</td>\n",
       "      <td>0</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.030359</td>\n",
       "      <td>0101000020E6100000F5A5CFA399243E40854A58CAE203...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp        lon        lat  \\\n",
       "0  1546300800   0.000000   0.000000   \n",
       "1  1546300800  30.136232  60.000054   \n",
       "2  1546300800  30.138478  59.835705   \n",
       "3  1546300800  30.142969  60.023627   \n",
       "4  1546300800  30.142969  60.030359   \n",
       "\n",
       "                                               point  hour  likescount  \\\n",
       "0  0101000020E61000000000000000000000000000000000...     0   31.666667   \n",
       "1  0101000020E6100000B8E59619E0223E40ABB649C80100...     0   52.000000   \n",
       "2  0101000020E610000077D0A94773233E4097654065F8EA...     0   32.000000   \n",
       "3  0101000020E6100000F5A5CFA399243E400B9A5B330603...     0   77.666667   \n",
       "4  0101000020E6100000F5A5CFA399243E40854A58CAE203...     0   19.000000   \n",
       "\n",
       "   commentscount  symbols_cnt  words_cnt  hashtags_cnt  mentions_cnt  \\\n",
       "0       1.666667    51.333333   2.000000      2.000000           0.0   \n",
       "1       1.000000    28.000000   0.500000      2.000000           0.0   \n",
       "2       0.333333    46.000000   2.333333      3.000000           0.0   \n",
       "3       3.333333    34.666667   2.666667      0.666667           0.0   \n",
       "4       3.000000     0.000000   0.000000      0.000000           0.0   \n",
       "\n",
       "   links_cnt  emoji_cnt  \n",
       "0        0.0   0.000000  \n",
       "1        0.0   0.500000  \n",
       "2        0.0   1.333333  \n",
       "3        0.0   1.666667  \n",
       "4        0.0   0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'timestamp' to a datetime format\n",
    "train_data['date'] = pd.to_datetime(train_data['timestamp'], unit='s')\n",
    "\n",
    "# Extracting the hour from the 'date' column\n",
    "train_data['hour'] = train_data['date'].dt.hour\n",
    "\n",
    "# Aggregate data based on 'hour', 'lon', and 'lat'\n",
    "agg_columns = {\n",
    "    'likescount': 'mean',\n",
    "    'commentscount': 'mean',\n",
    "    'symbols_cnt': 'mean',\n",
    "    'words_cnt': 'mean',\n",
    "    'hashtags_cnt': 'mean',\n",
    "    'mentions_cnt': 'mean',\n",
    "    'links_cnt': 'mean',\n",
    "    'emoji_cnt': 'mean',\n",
    "}\n",
    "\n",
    "grouped_data = train_data.groupby(['timestamp', 'lon', 'lat', 'point', 'hour']).agg(agg_columns).reset_index()\n",
    "grouped_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>point</th>\n",
       "      <th>hour</th>\n",
       "      <th>likescount</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>symbols_cnt</th>\n",
       "      <th>words_cnt</th>\n",
       "      <th>hashtags_cnt</th>\n",
       "      <th>mentions_cnt</th>\n",
       "      <th>links_cnt</th>\n",
       "      <th>emoji_cnt</th>\n",
       "      <th>publication_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0101000020E61000000000000000000000000000000000...</td>\n",
       "      <td>0</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.136232</td>\n",
       "      <td>60.000054</td>\n",
       "      <td>0101000020E6100000B8E59619E0223E40ABB649C80100...</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.138478</td>\n",
       "      <td>59.835705</td>\n",
       "      <td>0101000020E610000077D0A94773233E4097654065F8EA...</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.023627</td>\n",
       "      <td>0101000020E6100000F5A5CFA399243E400B9A5B330603...</td>\n",
       "      <td>0</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1546300800</td>\n",
       "      <td>30.142969</td>\n",
       "      <td>60.030359</td>\n",
       "      <td>0101000020E6100000F5A5CFA399243E40854A58CAE203...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp        lon        lat  \\\n",
       "0  1546300800   0.000000   0.000000   \n",
       "1  1546300800  30.136232  60.000054   \n",
       "2  1546300800  30.138478  59.835705   \n",
       "3  1546300800  30.142969  60.023627   \n",
       "4  1546300800  30.142969  60.030359   \n",
       "\n",
       "                                               point  hour  likescount  \\\n",
       "0  0101000020E61000000000000000000000000000000000...     0   31.666667   \n",
       "1  0101000020E6100000B8E59619E0223E40ABB649C80100...     0   52.000000   \n",
       "2  0101000020E610000077D0A94773233E4097654065F8EA...     0   32.000000   \n",
       "3  0101000020E6100000F5A5CFA399243E400B9A5B330603...     0   77.666667   \n",
       "4  0101000020E6100000F5A5CFA399243E40854A58CAE203...     0   19.000000   \n",
       "\n",
       "   commentscount  symbols_cnt  words_cnt  hashtags_cnt  mentions_cnt  \\\n",
       "0       1.666667    51.333333   2.000000      2.000000           0.0   \n",
       "1       1.000000    28.000000   0.500000      2.000000           0.0   \n",
       "2       0.333333    46.000000   2.333333      3.000000           0.0   \n",
       "3       3.333333    34.666667   2.666667      0.666667           0.0   \n",
       "4       3.000000     0.000000   0.000000      0.000000           0.0   \n",
       "\n",
       "   links_cnt  emoji_cnt  publication_count  \n",
       "0        0.0   0.000000                  3  \n",
       "1        0.0   0.500000                  2  \n",
       "2        0.0   1.333333                  3  \n",
       "3        0.0   1.666667                  3  \n",
       "4        0.0   0.000000                  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data['publication_count'] = train_data.groupby(['timestamp', 'hour', 'lon', 'lat', 'point']).size().values\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'timestamp' as it's strongly correlated with other time features and may cause data leakage\n",
    "X_train = grouped_data.drop(['publication_count', 'timestamp', 'point'], axis=1)\n",
    "y_train = grouped_data['publication_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'hour' column to a datetime format\n",
    "test_data['date'] = pd.to_datetime(test_data['hour'], unit='s')\n",
    "\n",
    "# Drop the original 'hour' column which contains the timestamp\n",
    "test_data.drop(columns=['hour'], inplace=True)\n",
    "\n",
    "# Extract the datetime features from the 'date' column\n",
    "test_data['hour'] = test_data['date'].dt.hour\n",
    "test_data['day'] = test_data['date'].dt.day\n",
    "test_data['dayofweek'] = test_data['date'].dt.dayofweek\n",
    "test_data['month'] = test_data['date'].dt.month\n",
    "\n",
    "# Drop the 'date' column as it's not needed for prediction\n",
    "test_data.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Set 'point' as the index for both datasets\n",
    "train_data.set_index('point', inplace=True)\n",
    "test_data.set_index('point', inplace=True)\n",
    "\n",
    "# List of features to create in the test dataset\n",
    "features_to_create = ['likescount', 'commentscount', 'symbols_cnt', 'words_cnt', \n",
    "                      'hashtags_cnt', 'mentions_cnt', 'links_cnt', 'emoji_cnt']\n",
    "\n",
    "# Aggregate the training dataset based on 'point' and compute the median for each feature\n",
    "aggregated_data = train_data[features_to_create].groupby('point').median()\n",
    "\n",
    "# Merge the test dataset with the aggregated training data on 'point'\n",
    "test_data = test_data.join(aggregated_data, on='point', how='left')\n",
    "\n",
    "# Reset index for both datasets after the operations\n",
    "train_data.reset_index(inplace=True)\n",
    "test_data.reset_index(inplace=True)\n",
    "\n",
    "X_test = test_data.drop(['sum', 'point', 'error'], axis=1)\n",
    "y_test = test_data['sum']\n",
    "X_test = X_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [1. Data Scaling] ----\n",
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scale the training and test data to [0, 1].\n",
    "    Returns the scaled data and the scaler.\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [2. Creating a Windowed Dataset] ----\n",
    "def create_windowed_dataset(data, window_size):\n",
    "    \"\"\"\n",
    "    Transforms the data into a windowed dataset.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i : i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [3. Model Building] ----\n",
    "def build_rnn_model(input_shape, dropout_rate, l2_reg):\n",
    "    \"\"\"\n",
    "    Build and return an RNN model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, activation='relu', return_sequences=True, kernel_regularizer=l2(l2_reg), input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(SimpleRNN(50, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [4. Model Training] ----\n",
    "def train_model(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the model using TimeSeriesSplit.\n",
    "    Returns the trained model.\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_index, val_index in tscv.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=50, validation_data=(X_val_fold, y_val_fold), verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance.\n",
    "    \n",
    "    Returns:\n",
    "    - RMSE\n",
    "    - Relative Error\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    epsilon = 1e-10\n",
    "    errors = np.abs(y_pred.flatten() - y_true) / (y_pred.flatten() + epsilon)\n",
    "    avg_relative_error = np.mean(errors)\n",
    "    return rmse, avg_relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [6. Visualization of Loss] ----\n",
    "def plot_loss(model):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss.\n",
    "    \"\"\"\n",
    "    plt.plot(model.history.history['loss'], label='Train Loss')\n",
    "    plt.plot(model.history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- [7. Visualization of Predicted vs Actual] ----\n",
    "def plot_predictions(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Plot actual vs predicted values.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(y_true, label='Actual', color='blue')\n",
    "    plt.plot(y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Main Execution ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window size definition\n",
    "window_size = 10\n",
    "\n",
    "X_train_scaled, X_test_scaled, _ = scale_data(X_train, X_test)\n",
    "X_train_windows, y_train_windows = create_windowed_dataset(X_train_scaled, window_size)\n",
    "X_test_windows, y_test_windows = create_windowed_dataset(X_test_scaled, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_rnn_model((window_size, X_train_scaled.shape[1]), 0.2, 0.001)\n",
    "trained_model = train_model(model, X_train_windows, y_train_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test_windows)\n",
    "rmse, relative_error = evaluate_model(y_test_windows, y_pred)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Relative Error: {relative_error}\")\n",
    "plot_loss(trained_model)\n",
    "plot_predictions(y_test_windows, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_publications_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
